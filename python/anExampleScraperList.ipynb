{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "anExampleScraperList.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fAT7xLYe_scU"
      },
      "source": [
        "# An example scraper using a list\n",
        "\n",
        "The code below can be copied and adapted to create your own scraper.\n",
        "\n",
        "The first part installs all the libraries. I've kept this separate to the other parts so that you don't have to install them every time you want to run the scraper itself."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sE2vW-IX9kYX"
      },
      "source": [
        "#install the libraries \n",
        "#scraperwiki is a library for scraping webpages\n",
        "!pip install scraperwiki\n",
        "import scraperwiki\n",
        "#lxml.html is used to convert it into xml (more structured)\n",
        "import lxml.html\n",
        "#cssselect is used to drill down into that and find data in tags\n",
        "!pip install cssselect\n",
        "import cssselect\n",
        "#the pandas library which is used to work with data - we call it 'pd' here so we have to type less!\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MTFOTQUh2UH"
      },
      "source": [
        "## Using a list\n",
        "\n",
        "Below we write some code to create a list of counties that can be used to generate URLs on a karting site.\n",
        "\n",
        "We also store the 'base URL' that we will add to each item in the list to create a full URL."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RO6lht-cgc4A"
      },
      "source": [
        "#create a list of counties that we will need to generate URLs\n",
        "counties = [\"avon\",\"bedfordshire\",\"berkshire\",\"birmingham\"]\n",
        "#store the base URL we will add those to\n",
        "baseurl = \"http://www.uk-go-karting.com/tracks/\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sn8Zsx4fiC_u"
      },
      "source": [
        "## Using a loop\n",
        "\n",
        "Next we loop through each item in the list and add it to that base url using the `+` operator.\n",
        "\n",
        "We add a `print` function inside the loop to check that it works each time - and copy those links into a browser to check that they are the right links."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRa5dxGOg2ZI",
        "outputId": "2b6b2a74-0dba-4319-a805-184f526031e2"
      },
      "source": [
        "#start looping through our list\n",
        "for county in counties:\n",
        "  fullurl = baseurl+county\n",
        "  print(fullurl)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://www.uk-go-karting.com/tracks/avon\n",
            "http://www.uk-go-karting.com/tracks/bedfordshire\n",
            "http://www.uk-go-karting.com/tracks/berkshire\n",
            "http://www.uk-go-karting.com/tracks/birmingham\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5s0_uuJiNIl"
      },
      "source": [
        "## Scraping each URL as we loop\n",
        "\n",
        "Now that we know the loop works in generating the right URLs, we can extend the code inside the loop so that it *scrapes* each URL.\n",
        "\n",
        "At this point we are using some of the libraries we imported at the start. `scraperwiki.scrape()`, for example, is the `scrape()` function from the `scraperwiki` library. \n",
        "\n",
        "Let's look at the code first, and then explain it..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Yw0QKTJ_qpu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "278a4115-27d6-4a26-f0e9-52f04398f8e6"
      },
      "source": [
        "#start looping through our list\n",
        "for county in counties:\n",
        "  fullurl = baseurl+county\n",
        "  print(fullurl)\n",
        "  #Scrape the html at that url\n",
        "  html = scraperwiki.scrape(fullurl)\n",
        "  # turn our HTML into an lxml object\n",
        "  root = lxml.html.fromstring(html) \n",
        "  #The names are all in <h2> and then <a \n",
        "  #This targets the contents of those html tags\n",
        "  addresses = root.cssselect('h2 a')\n",
        "  #the results are always a list so we have to loop through it using a 'for' loop\n",
        "  for i in addresses:\n",
        "    #each item in the list is called i as it loops\n",
        "    print(i)\n",
        "    #on its own it looks odd, but we can attach .text_content() to translate it into text\n",
        "    address = i.text_content()\n",
        "    print(address)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://www.uk-go-karting.com/tracks/avon\n",
            "<Element h3 at 0x7fa3a64cb548>\n",
            "Avonmouth Way, Bristol, Avon BS11 9YA\n",
            "http://www.uk-go-karting.com/tracks/bedfordshire\n",
            "<Element h3 at 0x7fa3a6474bd8>\n",
            "Unit 27, Verey Road, Woodside Industrial Estate, Dunstable, Bedfordshire LU5 4TT\n",
            "http://www.uk-go-karting.com/tracks/berkshire\n",
            "<Element h3 at 0x7fa3a6a6f8b8>\n",
            "Cradock Road, Reading, Berkshire RG2 0EE\n",
            "http://www.uk-go-karting.com/tracks/birmingham\n",
            "<Element h3 at 0x7fa3a64cb8b8>\n",
            "Fazeley Street, Birmingham B5 5SE\n",
            "<Element h3 at 0x7fa3a64cbcc8>\n",
            "Adderley Road South, Birmingham B8 1AD\n",
            "<Element h3 at 0x7fa3a64cb548>\n",
            "Park Lane, Oldbury, Birmingham B69 4JX\n",
            "<Element h3 at 0x7fa3a6481ea8>\n",
            "Robeys Lane, Tamworth,  B78 1AR\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDFgv8F5kt6U"
      },
      "source": [
        "## The functions we are using\n",
        "\n",
        "Let's break some of this down.\n",
        "\n",
        "So `scraperwiki.scrape()` is the `scrape()` function from the `scraperwiki` library. The *ingredient* we give to that function is the URL we stored in the `fullurl` variable.\n",
        "\n",
        "The `scrape()` function basically fetches the whole webpage at a given address (the ingredient it's given).\n",
        "\n",
        "The results of running that function are stored in a new variable called `html`.\n",
        "\n",
        "This isn't in a form we can easily work with, yet, so we need another function to convert it to something we can drill down into. \n",
        "\n",
        "That function is the `fromstring()` function from the `lxml.html` library. The *ingredient* we give to that function is the `html` variable we just created.\n",
        "\n",
        "The results are stored in another new variable, `root`.\n",
        "\n",
        "This variable is a particular type of object (an \"lxml object\" if you need to know) that can be drilled down into using the `cssselect` function. That function will grab elements that match the *CSS selectors* that you give it as an ingredient.\n",
        "\n",
        "In this case we specify `'h2'`, which means \"any h2 tag\" - so it will grab the contents of any h2 tags in the page.\n",
        "\n",
        "Don't worry about memorising any of the code above: this is code that you can re-use time and time again. The only bit you will need to change is the selector, in order to specify the particular HTML you're after. \n",
        "\n",
        "To work out the selector you need, you'll often need to Google around, learning as you go, but selectors are pretty easy to get the hang of, and I'll talk about it more below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1n21e_LWI-A"
      },
      "source": [
        "## Using CSS selectors\n",
        "\n",
        "**CSS selectors** are used to target different elements in a HTML page. A basic selector can target just one type of HTML tag, like `<h2>` or `<p>`, but you can also target a combination of tags (such as any `<strong>` tags within `<p>` tags). \n",
        "\n",
        "More complicated selectors can also be used to target tags based on their attributes (e.g. not just `<p>` but specifically `<p class=\"summary\">`).\n",
        "\n",
        "You can find lots of resources to help you with CSS selectors, such as [this one](https://www.w3schools.com/cssref/css_selectors.asp). Many will relate to styling webpages (which is how CSS selectors are most often used - selectors are used to target the HTML elements that you want to style), but the principles are the same.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQpygiZfYeT4"
      },
      "source": [
        "## Saving the information we've grabbed.\n",
        "\n",
        "Now we've grabbed some information we can extend the code further to save it.\n",
        "\n",
        "At this point we need to use functions from another library: `pandas`. This is a library for data storage and analysis. When we imported `pandas` we called it `pd` for short. This is quite common. Any reference to `pd` in the code, then, means `pandas`\n",
        "\n",
        "First, we use the function `DataFrame()` which creates a pandas dataframe. As ingredients it needs to know the names of any columns.\n",
        "\n",
        "You will see below that we add a line *before* the loop which uses that to create an empty dataframe to store the data in.\n",
        "\n",
        "Then, inside the loop, the data we extract is added to the dataframe.\n",
        "\n",
        "Here's the code first - then I'll explain the new bits after.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c_hvHkNqhc0B"
      },
      "source": [
        "#Create a dataframe to store the data we are about to scrape\n",
        "#It has one column called 'title'\n",
        "#We call this dataframe 'df'\n",
        "df = pd.DataFrame(columns=[\"location\"])\n",
        "\n",
        "#start looping through our list\n",
        "for county in counties:\n",
        "  fullurl = baseurl+county\n",
        "  print(fullurl)\n",
        "  #Scrape the html at that url\n",
        "  html = scraperwiki.scrape(fullurl)\n",
        "  # turn our HTML into an lxml object\n",
        "  root = lxml.html.fromstring(html) \n",
        "  #There are 100 recordings on the page\n",
        "  #The titles are all in <div class=\"title\"> and then <a \n",
        "  #This targets the contents of those html tags\n",
        "  addresses = root.cssselect('h3')\n",
        "  #the results are always a list so we have to loop through it using a 'for' loop\n",
        "  for i in addresses:\n",
        "    #each item in the list is called i as it loops\n",
        "    print(i)\n",
        "    #on its own it looks odd, but we can attach .text_content() to translate it into text\n",
        "    address = i.text_content()\n",
        "    print(address)\n",
        "    #Now we need to store it in that variable called 'df' \n",
        "    df = df.append({\n",
        "      \"location\" : address\n",
        "      }, ignore_index=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "omuqBRQKZW8h"
      },
      "source": [
        "## The new code\n",
        "\n",
        "The first line of new code is this:\n",
        "\n",
        "`df = pd.DataFrame(columns=[\"title\"])`\n",
        "\n",
        "We are creating a new variable here, called `df`, and assigning to it the results of using a function: `pd.DataFrame()` (the `pandas` function `DataFrame`).\n",
        "\n",
        "That takes an ingredient which specifies the columns as being a list (note the square brackets) of one string: `\"title\"`.\n",
        "\n",
        "The second line of new code is this:\n",
        "\n",
        "```\n",
        "df = df.append({\n",
        "      \"title\" : title\n",
        "      }, ignore_index=True)\n",
        "```\n",
        "\n",
        "This takes the `df` variable and updates it. \n",
        "\n",
        "On the right of the equals sign is `df.append()` - this means it is using a function called `append` to append (add) new data to the `df` variable it's attached to.\n",
        "\n",
        "The `append` function [can include various ingredients](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.append.html): firstly the data that you want to append to the dataframe; but also settings, such as whether you want something called `ignore_index` to be `True` or `False`. Setting this to `True` just avoids problems when your data isn't unique.\n",
        "\n",
        "What about the data that you are appending? Well, this has to be in the form of a **dictionary**. A dictionary is like a list, but with two key differences: firstly that it uses curly brackets instead of square ones: `{}`, and secondly it's a list of *pairs*: a 'key', and a 'value', separated by a colon.\n",
        "\n",
        "Here's the dictionary in our code:\n",
        "\n",
        "`{\"title\" : title}`\n",
        "\n",
        "The first part, `\"title\"` is the **key**. This matches the column heading in the empty data frame. Note that it's a **string**: a label, basically.\n",
        "\n",
        "The second part, `title`, is the **value**. This isn't in quotes so it's not a string - it's a variable. A few lines earlier we created this variable with `title = i.text_content()`\n",
        "\n",
        "So having extracted that information and stored it in `title`, the line of code is storing it in a dataframe with the label (key) \"title\":\n",
        "\n",
        "```\n",
        "df = df.append({\n",
        "      \"title\" : title\n",
        "      }, ignore_index=True)\n",
        "```\n",
        "\n",
        "We can print the dataframe to see what's in there:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIdecPU__881",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fae228db-5dd0-4814-f92f-179955b5b77a"
      },
      "source": [
        "#Once the loop has finished we can take a look at the data\n",
        "print(df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  title                                           location\n",
            "0   NaN              Avonmouth Way, Bristol, Avon BS11 9YA\n",
            "1   NaN  Unit 27, Verey Road, Woodside Industrial Estat...\n",
            "2   NaN           Cradock Road, Reading, Berkshire RG2 0EE\n",
            "3   NaN                  Fazeley Street, Birmingham B5 5SE\n",
            "4   NaN             Adderley Road South, Birmingham B8 1AD\n",
            "5   NaN             Park Lane, Oldbury, Birmingham B69 4JX\n",
            "6   NaN                    Robeys Lane, Tamworth,  B78 1AR\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bh73Sbovc9To"
      },
      "source": [
        "## Exporting the data\n",
        "\n",
        "The `pandas` library has another function for exporting data: `to_csv()`.\n",
        "\n",
        "It needs to be attached to the name of the dataframe variable with a period, then, in the brackets, you specify the name of the file you want to export it as. Make sure this ends in '.csv' so it can be used in a spreadsheet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9FDGDX0__eA"
      },
      "source": [
        "#And we can export it\n",
        "df.to_csv(\"scrapeddata.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCtq8ih5dNaE"
      },
      "source": [
        "## Downloading the data\n",
        "\n",
        "Once exported, it should appear in the file explorer in Google Colab on the left hand side. Click on the folder icon to open this up and you should see the file you just created (there's a refresh button above if you can't).\n",
        "\n",
        "Hover over the file name to see three dots, then click on those to select **Download** and download to your computer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eq60rrHrAoeN"
      },
      "source": [
        "## How to adapt it\n",
        "\n",
        "You can use most of this code without having to change it. All you *need* to change is the lines specifying the base URL, and the list of words to add to it.\n",
        "\n",
        "And this line, which specifies what you want to scrape from that page:\n",
        "\n",
        "`titles = root.cssselect('h2')`\n",
        "\n",
        "If you're scraping one type of information from one page, that will be enough. \n",
        "\n",
        "For the CSS selector you will need to identify the HTML in the page you are scraping, and the combination of tags that is being used. \n",
        "\n",
        "Some [reading around CSS selectors](https://www.w3schools.com/cssref/css_selectors.asp) will help you here, but a couple of useful things to know include:\n",
        "\n",
        "* A period `.` means `class=\"`\n",
        "* A hash `#` means `id=\"`\n",
        "\n",
        "So `'div.title a'` means `<div class=\"title\"><a ...>` - or, in other words, anything on the page inside an `<a>` tag (a link) within a `<div class=\"title\">` tag.\n",
        "\n",
        "The words used for variables (like \"baseurl\" and \"titles\" above) may not be relevant to what you are scraping - but that doesn't matter, because those words are arbitrary. If you do decide to change them, make sure you change them *throughout* the code, or it will create an error.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nE35f1sxgV6Q"
      },
      "source": [
        "## Generating URLs for a scraper to loop through\n",
        "\n",
        "Alternatively you might *generate* the URLs: for example, if they end in a number that goes up by 1 each time you can use `range` to generate that list of numbers and add them to the URL using `+`.\n",
        "\n",
        "However, you cannot mix numbers and strings, so you need to convert the numbers to a string as you do this. Here's an example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUcpB_cPNwq5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "b7183717-1963-44bd-b23c-108433c48c7b"
      },
      "source": [
        "#Create the basic URL that appears before the number\n",
        "baseurl = \"http://mypage.com?page=\"\n",
        "#Create a list of numbers to put on the end\n",
        "pagenums = range(1,11)\n",
        "#Now generate the URLs by looping through the list and adding it to the URL\n",
        "for i in pagenums:\n",
        "  #Combine the two - \n",
        "  #this will generate an error because we are trying to combine a string and a number\n",
        "  fullurl = baseurl+i"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-5-fe2fd370c033>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;31m#Combine the two -\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0;31m#this will generate an error because we are trying to combine a string and a number\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mfullurl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbaseurl\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: must be str, not int"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KshYh7u7ON5d"
      },
      "source": [
        "## Tip: converting numbers into strings\n",
        "\n",
        "You can see the error `must be str, not int` - in other words the second part must be a string not an integer.\n",
        "\n",
        "To fix that you can use the `str()` function, which will convert a number into a string."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HyuZ131lOW3w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "475d3e46-8694-42eb-f546-23e7cc7882d5"
      },
      "source": [
        "#Create the basic URL that appears before the number\n",
        "baseurl = \"http://mypage.com?page=\"\n",
        "#Create a list of numbers to put on the end\n",
        "pagenums = range(1,11)\n",
        "#Now generate the URLs by looping through the list and adding it to the URL\n",
        "for i in pagenums:\n",
        "  #Convert i to a string\n",
        "  i = str(i)\n",
        "  #Combine the two\n",
        "  fullurl = baseurl+i\n",
        "  #print it\n",
        "  print(fullurl)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "http://mypage.com?page=1\n",
            "http://mypage.com?page=2\n",
            "http://mypage.com?page=3\n",
            "http://mypage.com?page=4\n",
            "http://mypage.com?page=5\n",
            "http://mypage.com?page=6\n",
            "http://mypage.com?page=7\n",
            "http://mypage.com?page=8\n",
            "http://mypage.com?page=9\n",
            "http://mypage.com?page=10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOvob6z3hEmq"
      },
      "source": [
        ""
      ]
    }
  ]
}